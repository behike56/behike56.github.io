---
layout: post
title:  "EKSアップグレード"
date:   2024-06-27 00:00:00 +0900
categories: jekyll update
tags:
- Kubernetes
---

## 目次

1. 変数とCLI
2. EKSのバックアップ
3. クラスターアプグレード
4. アドオンアップグレード
5. 正常性確認
6. 切り戻し (EKSアップグレード)

## 1. 変数とCLI

### 変数の設定

``` zsh
#　一覧
kubectl config get-contexts

#　バックアップ対象のクラスターのコンテキスト
# user_A@dev-prj-name-eks-cluster01.ap-northeast-1.eksctl.io
export PRIMARY_CONTEXT=ユーザーID@クラスター名.リージョン名.クラスター管理ツール
# バックアップ名
export ACKUP_NAME=cdp-backup-eks-2024xxxxxxx

# バックアップファイルがあるバケット名
export BACKUP_BUCKET="test-dev-prj-name-eks-backup"

# 環境変数でデフォルトリージョンを設定
export AWS_DEFAULT_REGION=ap-northeast-1

export CLUSTER_NAME=dev-prj-name-eks-cluster01

export NODE_GROUP_NAME1=dev-prj-name-eks-cluster01-mng01
export NODE_GROUP_NAME2=dev-prj-name-eks-cluster01-mng02
export NODE_GROUP_NAME3=dev-prj-name-eks-cluster01-mng03
export NODE_GROUP_NAME4=dev-prj-name-eks-cluster01-mng04
export NODE_GROUP_NAME5=dev-prj-name-eks-cluster01-mng05
export NODE_GROUP_NAME6=dev-prj-name-eks-cluster01-mng06
```

### kubectl

``` zsh
https://kubernetes.io/ja/docs/tasks/tools/install-kubectl/
kubectl のインストールまたは更新- Amazon EKS 
```

### AWS CLI

``` zsh
#　現在のバージョンの確認
aws --version

# AWS CLI2のアップデート
curl "https://awscli.amazonaws.com/awscli-exe-linux-x86_64-2.15.15.zip" -o "awscliv2.zip"

# エラーが発生しないことを確認
unzip awscliv2.zip

# エラーが発生しないことを確認
sudo ./aws/install --update

# エラーが発生しないことを確認
source ~/.bash_profile

# 2.15.15になっていること
aws --version
```

### eksctl

``` zsh
# ver check
eksctl version

# 作業ディレクトリに移動
cd ~/work/sre/2024{MMDD}_EKS_upgrade_1.26

# 既存コマンドのバックアップを取得
mkdir eksctl_backup_0155.0

# エラーが発生しないことを確認
cp /usr/local/bin/eksctl eksct1_backup_0.155.0

#アップグレード (エラーが発生しないことを確認)※ver指定したコマンドで試打
curl --silent --location "https://github.com/weaveworks/eksct1/releases/download/v0.168.0/eksctl_$(uname -s)_amd64.tar.gz" | tar xz -C /tmp

#エラーが発生しないことを確認
cp /tmp/eksctl /usr/local/bin

# v0.168.0になっていることを確認する
eksctl version

#後始末
rm ./eksctl
```

### velero CLI

``` zsh
# 現在のverを確認
velero version--client-only

# 既存コマンドのバックアップを取得
mkdir velero_backup
cp/usr/local/bin/velero velero_backup

# アップグレード
curl -fsSL -o velero-v1.13.0-linux-amd64.tar.gz https://github.com/vmware-tanzu/velero/release
tar zxvf velero-v1.13.0-linux-amd64.tar.gz
cp velero-v1.13.0-linux-amd64/velero /usr/local/bin/velero

# v1.13.0になっていることを確認する
velero version --client-only
```

## 2. EKSのバックアップ

### ストアしないリソースを設定

``` zsh
# ClusterAutoScalerがveleroでバックアップされないようにする (リストア時の新旧クラスター競合防止) 
kubectl patch deployment cluster-autoscaler-aws-cluster-autoscaler \
    -n kube-system \
    -p '{"metadata":{"labels":{"velero.io/exclude-from-backup":"true"}}}'

# ClusterAutoScalerがveleroでバックアップされないようにする (リストア時の新旧クラスター競合防止) 
kubectl patch svc cluster-autoscaler-aws-cluster-autoscaler \
    -n kube-system \
    -p '{"metadata":{"labels":{"velero.io/exclude-from-backup": "true"}}}'
```

### veleroコマンド実行

``` zsh
# エラーが発生しないことを確認
kubectl config use-context $PRIMARY_CONTEXT

# エラーが発生しないことを確認
velero backup create $BACKUP_NAME

# PhaseがCompletedになるまで待つ(2 ~ 3 分程度)
velero backup describe $BACKUP_NAME

----
Name:　cdp-backup-eks-20220927-before-addon
Namespace: velero
Labels:　velero.io/storage-location-default
Annotations:
    velero.io/source-cluster-k8s-gitversion=v1.21.14-eks-18
    velero.io/source-cluster-k8s-major-version=1 
    velero.io/source-cluster-k8s-minor-version=21+
Phase: Completed
Errors:
...
---

#S3バケットにバックアップが入っていることを確認する
aws s3 ls $BACKUP_BUCKET/backups/$BACKUP_NAME/
---
2022-09-27 10:01:27 29 cdp-backup-eks-20221005-before-addon-cs 
2022-09-27 10:01:27 29 cdp-backup-eks-20221005-before-addon-cs
2022-09-27 10:01:27 45155 cdp-backup-eks-20221005-before-addon-cs
2022-09-27 10:01:27 29 cdp-backup-eks-20221005-before-addon-lc 
2022-09-27 10:01:27 29 cdp-backup-eks-20221005-before-addon-pc 
2022-09-27 10:01:27 1043588 cdp-backup-eks-20221005-before-addon-re 
2022-09-27 10:01:27 10225 cdp-backup-eks-20221005-before-addon-vo 
---
```

## 3. Cluster

### Cluster

``` zsh
# アップグレード確認
eksctl upgrade cluster --name=$CLUSTER_NAME --version=1.26
```

### クラスターアップグレード実行

``` zsh
# 完了までに10分程度かかる
eksctl upgrade cluster --name=$CLUSTER_NAME --version=1.26 --approve
```

### ノードグループアップグレード

アップグレード対象のノードグループの最大サイズを希望サイズの2倍以上にする.

prj-name-manifestの定義値を確認する
PodDisruptionBudget minAvailable Deployment replicas HPAutoscaler minRe
合、下記対応を実施する。
瞬断されたくないアプリの場合:
・Deployment replicas HPAutoscaler minReplicas Pod Disruption Budget mi
する
瞬断されてもいいアプリの場合:
・PodDisruption Budget を削除する

### ノードグループ1~Nのアップグレード

``` zsh
# 完了までに36分程度かかる
eksctl upgrade nodegroup \
    --name=$NODE_GROUP_NAME1 \
    --cluster=SCLUSTER NAME \
    --kubernetes-version=1.26
```

### バックアップ取得

``` zsh
cd work

# 既存コマンドのバックアップを取得
mkdir kubectl backup

# エラーが発生しないことを確認
cp /usr/local/bin/kubectl kubectl_backup
```

### 正しいURLからダウンロードしているか確認

デバイスのハードウェアプラットフォームのコマンドを使用して、クラスターのKubernetes バージョンの kubect1 バイナリを Amazon S3からダウンロードします。
`curl -o https://s3.us-west-2.amazonaws.com/amazon-eks/1.26.10/2023-11-14/bin/darwin/amd64/kubectl`

ダウンロードしたバイナリを、バイナリの SHA-256 チェックサムで検証します。
`curl -o https://s3.us-west-2.amazonaws.com/amazon-eks/1.26.10/2023-11-14/bin/darwin/amd64/kubectl.sha256`

ダウンロードしたバイナリのSHA-256 チェックサムを確認します。

``` zsh
# kubect1: OKになることを確認
sha256sum -c kubectl. sha256
```

適用する階層に移動して、適用
`sudo cp/work/kubectl /usr/local/bin/kubectl`

バージョン確認
※v1.26.10になっていること
`kubectl version --short --client`

## 4. アドオンアップグレード

### AWSアドオンアップグレード

#### Amazon VPC CNIの更新

(Amazon VPC CNI plugin for Kubernetes Amazon EKS アドオンの使用 - Amazon EKS)[]

1. 対応前の以下の状態をそれぞれ確認
    a. Podの状態(対応後にAGEが変わっている事を比較するため)
        `kubectl get pod -n kube-system -o wide -l k8s-app=aws-node`
    b.aws-nodeのバージョンを確認
        `kubectl get pods -l k8s-app=aws-node -n kube-system -o jsonpath="{.items[*].spec.containers[*].image} | tr -s '[[:space:]]' '\n' && echo`
2. EKSコンソールからアドオンタブを開いて 「vpc-cni」 を選択し、「編集」を押下
3. 以下を選択して、「更新」を押下
    a. バージョン v1.16.0-eksbuild.1
    b. サービスアカウントロール-ノードから継承
    c. クラスター上のこのアドオンの既存の設定を上書きします。 → チェックボックス有効化
4. EKSコンソールのアドオンタブ画面の[Amazon VPC CNI]のステータスが完了になったことを確認(最大 で15分程度かかる)
5. 踏み台から以下コマンドを実行して、 Podが更新されている事を確認
    a. AGEが更新されている事
        `kubectl get po -n kube-system -o wide -l k8s-app=aws-node`
    b. v1.16.0-eksbuild.1 のイメージが使われている事
        `kubectl get pods -l k8s-app=aws-node-n kube-system-o jsonpath="{.items[*].spec.containers[*].image}" | tr -s '[[:space]]' '\n' && echo`

#### kube-proxyの更新

(Kubernetes kube-proxy アドオンの使用 Amazon EKS)[]

1. 対応前の以下の状態をそれぞれ確認
    a. Podの状態 (対応後にAGEが変わっている事を比較するため)
        `kubectl get pod -n kube-system -o wide -l k8s-app=kube-proxy`
    b. kube-proxyのバージョンを確認
        `kubectl get pods -l k8s-app=kube-proxy -n kube-system -o jsonpath="{.items[*].spec.contaers[*].image}" | tr -s '[[:space]]' '\n' && echo`
2. EKSコンソールからアドオンタブを開いて 「kube-proxy」 を選択し、「編集」を押下
3. 以下を選択して、「バージョンの更新」を押下
    a. バージョン`v1.26.11-eksbuild.1`
    b. サービスアカウントロールノードから継承
    c. クラスター上のこのアドオンの既存の設定を上書きします。→ チェックボックス有効化
4. EKSコンソールのアドオンタブ画面の[Amazon VPC CNI]のステータスが完了になったことを確認(最大で15 分程度かかる)
5. 踏み台から以下コマンドを実行して、 Podが更新されている事を確認
    a. AGEが更新されている事
        `kaget pod -n kube-system -l k8s-app=kube-proxy`
    b. v1.26.11-minimal-eksbuild.1 のイメージが使われている事
        `kubectl get pods -l k8s-app=kube-proxy -n kube-system -o jsonpath="{.items[*].spec.containers[*].image}" | tr -s '[[:space]]' '\n' && echo`

#### CoreDNSの更新

(CoreDNS Amazon EKS アドオンの使用 Amazon EKS)[]

1. 対応前の下の状態をそれぞれ確認
    a. Podの状態 (対応後にAGEが変わっている事を比較するため)
        `kubectl get pod -n kube-system -o wide -l k8s-app=kube-dns`
    b. coreDNSのバージョンを確認
        `kubectl get pods -l k8s-app=kube-dns -n kube-system -o jsonpath="{.items[*].spec.containers[*].image}" | tr -s '[[:space:]]' '\n' && echo`
2. EKSコンソールからアドオンタブを開いて 「CoreDNS」を選択し、 「編集」を押下
3. 以下を選択して、「更新」を押下
    a. バージョン」 → `v1.9.3-eksbuild.10`
    b. サービスアカウントロールーノードから継承
    c. クラスター上のこのアドオンの既存の設定を上書きします。→チェックボックス有効化
4. EKSコンソールのアドオンタブ画面の [CoreDNS]のステータスが完了になったことを確認(最大で15分 程度かかる)
5. 踏み台から以下コマンドを実行して、 Podが更新されている事を確認
    a. AGEが更新されている事
        `kubectl get pod -n kube-system -o wide-1 k8s-app=kube-dns`
    b. v1.9.3-eksbuild.10 のイメージが使われている事
        `kubectl get pods -l k8s-app=kube-dns -n kube-system -o jsonpath="{.items[*].spec.containers[*].image}" | tr -s '[[:space:]]' '\n' && echo`

### 独自アドオンアップグレード

システムマニフェストのプルリクエストをマージする

#### ArgoCDのログイン

`argocd login --username admin --passwordk -n argocd get secret argocd-initial-admin-secret`

#### istio-operatorのアップグレード確認(1.25 -1.26)

※1.20.2になっていること

``` zsh
# 手動sync実行
argood app get istio-operator --port-forward-namespace argocd

#istio-operatorのポッドが正常に起動していること (READYが1/1、 STATUSがRunningであること)を確認
kubectl get pod -n istio-operator
NAME READY STATUS RESTARTS AGE
istio-operator-dcb58f84c-szbgz 1/1 Running 0 8s
```

#### Cluster AutoScalerのアップグレード

v1.26.2 (helm9.28.0)

``` zsh
# 事前にクラスターオートスケーラーのARN確認
k describe sa cluster-autoscaler-aws-cluster-autoscaler -n kube-system
```

``` zsh
#クラスターオートスケーラーのIAM サービスアカウント(上記で確認したARN)
IAM_SERVICE_ACCOUNT_ARN=arn: aws:iam::1234567890:role/eksctl-dev-prj-name-eks-cluster01-addon-1

#クラスターオートスケーラーのバージョンを設定する
VERSION TAG=v1.26.2

# クラスター名
CLUSTER_NAME=dev-prj-name-eks-cluster01
```

#### マージ後に以下のコマンドを叩いてverを確認

``` zsh
# argoCD App作成(自動デプロイ無効) (エラーが発生しないことを確認)
argocd app create cluster-autoscaler
    --label category-addon \
    --repo https://kubernetes.github.io/autoscaler \
    --helm-chart cluster-autoscaler \
    --revision 9.28.0 \
    --helm-set autoDiscovery.clusterName=$CLUSTER_NAME \
    --helm-set awsRegion-ap-northeast-1 \
    --helm-set image.tag=$VERSION_TAG \
    --helm-set rbac.serviceAccount.annotations."eks\.amazonaws.com/role-arn"=$IAM_SERVICE_ACCOUNT \
    --helm-set extraArgs.skip-nodes-with-local-storage=false \
    --dest-namespace kube-system \
    --dest-server https://kubernetes.default.svc \
    --port-forward-namespace argocd \
    --upsert

# Syncコマンド(デプロイ実行) (エラーが発生しないことを確認)
argocd app sync cluster-autoscaler --prune --port-forward-namespace argocd

# Synced, Healthyであることを確認する。
argocd app list --port-forward-namespace argocd | grep cluster-autoscaler

# Pod削除制限オプション。 Helmでは設定が出来ないため、手動にて実行
kubectl patch deployment cluster-autoscaler-aws-cluster-autoscaler \
    -n kube-system \
    -p '{"spec":{"template":{"metadata": {"annotations":{"cluster-autoscaler.kubernetes.io/safe-to-evict": "false"}}}}}'

#バージョンが1.26.2であることを確認する
kubectl describe deployment cluster-autoscaler-aws-cluster-autoscaler -n kube-system | grep Image:

Image: k8s.gcr.io/autoscaling/cluster-autoscaler:v1.26.2

#ポッドが正常に起動していること(READYが1/1、STATUSがRunningであること)を確認
# AGEがマージ後の時間であることを確認する
kubectl get po -n kube-system | grep cluster-autoscaler

cluster-autoscaler-aws-cluster-autoscaler 1/1 Running 1 (4h51m ago)
```

### LBコントローラー

#### LBC 実施

``` zsh
argocd app create aws-load-balancer-controller \
    --label category=addon \
    --repo https://aws.github.io/eks-charts \
    --helm-chart aws-load-balancer-controller
    --revision 1.6.2 \
    --helm-set clusterName=$CLUSTER_NAME \
    --helm-set serviceAccount.create=false\
    --helm-set serviceAccount.name=aws-load-balancer-controller \
    --helm-set podDisruptionBudget.maxUnavailable=1 \
    --dest-server https://kubernetes.default.svc \
    --dest-namespace kube-system \
    --sync-policy automated \
    --port-forward-namespace argocd \
    --auto-prune \
    --upsert

# Synced, Healthy Auto-Prune
argocd app list --port-forward-namespace argocd | grep aws-load-balancer-controller
```

#### LBC 結果確認

``` zsh
# PodDisruptionBudget (aws-load-balancer-controller) EL<ENTUSSLERT3
# MAX UNAVAILABLE 1 ALLOWED DISRUPTIONS_LEMRT3.
kubectl get pdb -n kube-system

NAME MIN AVAILABLE MAX UNAVAILABLE ALLOWED DISRUPTI
aws-load-balancer-controller N/A 1 1

# Imageのバージョンがv2.6.2であることを確認する
kubectl describe deployment aws-load-balancer-controller -n kube-system | grep Image:
Image: 602401143452.dkr.ecr.us-west-2.amazonaws.com/amazon/aws-load-balancer-control

# READYが1/1 Runningであることを確認する
# AGEがマージ後の時間であることを確認する
kubectl get pod -n kube-system | grep aws-load-balancer-controller
aws-load-balancer-controller 1/1 Running 0
aws-load-balancer-controller 1/1 Running 10
```

### datadog アップグレード

※Datadog agentの瞬断が発生しアラートが上がる可能性がある

#### datadog 実施

``` zsh
#ArgoCD App作成(エラーが発生しないことを確認)
argocd app create datadog-agent \
    --label category=addon \
    --rehttps://helm.datadoghq.com \
    --helm-chart datadog \
    --revision 3.52.0 \
    --helm-set datadog.apiKey=$DATADOG_API_KEY \
    --helm-set clusterAgent.tolerations[0].operator=Exists \
    --helm-set agents.tolerations[0].operator=Exists \
    --helm-set clusterChecksRunner.tolerations[0].operator=Exists \ 
    --dest-namespace kube-system \
    --dest-server https://kubernetes.default.svc \
    --sync-policy automated \
    --upsert

# Synced, Healthy, Auto-Prune
argocd app list --port-forward-namespace argocd | grep datadog-agent
```

#### datadog 結果確認

``` zsh
# Imageのバージョンが7.50.3であることを確認する
kubectl describe daemonset datadog-agent -n kube-system | grep Image:

Image: gcr.io/datadoghq/agent:7.50.3
Image: gcr.io/datadoghq/agent:7.50.3
Image: gcr.io/datadoghq/agent:7.50.3
Image: gcr.io/datadoghq/agent:7.50.3
Image: gcr.io/datadoghq/agent:7.50.3

# Podが起動していることを確認する (datadog-agent-cluster-agent の READYが1/1、 すべてのdatadog-agen 
# AGEがマージ後の時間であることを確認する
kubectl get pod -n kube-system

NAME READY STATUS RESTARTS
datadog-agent-123 3/3 Running 0
datadog-agent-123 3/3 Running 10
datadog-agent-cluster-agent-1231/1 Running 20
datadog-agent-123 3/3 Running 0
datadog-agent-123 3/3 Running 0
datadog-agent-123 3/3 Running 0
```

### ArgoCD 実施

上で実施したprj-name-system-manifestのマージで同時にアップグレード済み

### ArgoCD 結果確認

``` zsh
# Imageのバージョンがv2.9.5であることを確認する
kubectl describe deployment argocd-server -n argocd | grep Image:
Image: quay.io/argoproj/argocd: v2.9.5

# Podが起動していることを確認する (READYが1/1で、 STATUSがRunning)
# AGEがマージ後の時間であることを確認する
kubectl get pod -n argocd

NAME READY STATUS RESTARTS AGE
argocd-application-controller1/1 Running 0 4h40m
argocd-dex-server 1/1 Running 0 4h37m
argocd-redis 1/1 Running 10 4h37m
argocd-server 1/1 Running 1 (4h39m ago) 4h40m
argocd-applicationset-controller 1/1 Running 10 4h43m
argocd-notifications-controller 1/1 Running 0 4h43m
argocd-repo-server 1/1 Running 0 4h43m
```

#### metrics server 実施

``` zsh
# argocD App作成 (エラーが発生しないことを確認)
argocd app create metrics-server \
    --label category=addon \
    --rehttps://kubernetes-sigs.github.io/metrics-server/ \
    --helm-chart metrics-server \
    --revision 3.11.0 \
    --dest-namespace kube-system \
    --dest-server https://kubernetes.default.svc \
    --sync-policy automated \
    --port-forward-namespace argocd \
    --auto-prune \
    --upsert

# Synced, Healthy, Auto-PruneŁEMRTZ.
argocd app list --port-forward-namespace argocd | grep metrics-server
```

#### metrics server 結果確認

``` zsh
# バージョンがve.6.4であることを確認する
kubectl describe deployment metrics-server -n kube-system | grep Image:

Image: k8s.gcr.io/metrics-server/metrics-server:v0.6.4

# metrics-serverのPodが正常に動作していること(READYが1/1, STATUSがRunningであること)を確認￥ 
# AGEがマージ後の時間であることを確認する
kubectl get pod -n kube-system

NAME READY STATUS RESTARTS AGE
metrics-server 1/1 Running 1 (10h ago) 10h
```

#### fluent-bit 実施

上で実施したprj-name-system-manifestのマージで同時にアップグレード済み

#### fluent-bit 結果確認

``` zsh
# バージョンが1.3.18であることを確認する
kubectl describe daemonset fluent-bit -n amazon-cloudwatch | grep CI_VERSION:

CI VERSION: k8s/1.3.18

#fluent-bitのポッドが正常に起動していること(READYが1/1、STATUS が Runningであること)を確認
# AGEがマージ後の時間であることを確認する
kubectl get pod -n amazon-cloudwatch

NAME READY STATUS RESTARTS AGE
fluent-bit-a 1/1 Running 0 10h
fluent-bit-b 1/1 Running 0 11h
fluent-bit-c 1/1 Running 0 10h
fluent-bit-d 1/1 Running 0 11h
fluent-bit-e 1/1 Running 0 11h
fluent-bit-f 1/1 Running 0 10h
fluent-bit-g 1/1 Running 0 11h
fluent-bit-h 1/1 Running 0 10h
```

## 5. 正常性確認

- Podがすべて正常に動いていること
    `kubectl get pod--all-namespaces`
- DataDog backlogにエラーが出ていないこと
- ArgoCDのアプリの正常性確認
  - ArgoCDのログインを再度実施する(手順は「ArgoCDのログイン方法」を参照)
  - Argo CD のアプリの STATUS が Synced HEALTH が Healthy であることを確認する。 ArgoCDOJUD
    ※ aws-load-balancer-controllerとistio-operator datadog-agent は outofsync の可能性あり

- 上で STATUS が Synced、HEALTH が Healthy 以外のアプリがあった場合のみ以下のコマンドを実行する。 
  - 実行後再度上記の argocd app list を実行し STATUS が Synced 、 HEALTH が Healthy であることを確認する。
    `argocd app sync アプリ名 --prune --port-forward-namespace argocd`
    ※問題があれば切り戻しをする。 切り戻しは 「切り戻し (EKSアップグレード)」 を参照すること

## 6. 切り戻し (EKSアップグレード)

EKSのクラスターとノードグループが失敗した場合はAWSが自動で切り戻してくれる。
